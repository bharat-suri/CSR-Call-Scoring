# -*- coding: utf-8 -*-
"""TrainModel

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1JkW85J7ZhjzUcKk7sSf8mSfFK6svNtND
"""

from __future__ import unicode_literals, print_function, division
from io import open
import unicodedata
import string
import re
import random

import torch
import torch.nn as nn
from torch import optim
import torch.nn.functional as F

from tqdm import tqdm

from Inference_fns import get_accuracy

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

def train_model(dataloader_train, encoder, classifier):

  criterion = nn.CrossEntropyLoss()

  encoder_optimizer = optim.Adam(encoder.parameters(), lr=0.001)
  classifier_optimizer = optim.Adam(classifier.parameters(), lr=0.001)

  epochs = 10
  for n in range(epochs):
      epoch_loss = 0
      for batch in tqdm(dataloader_train):
          encoder.zero_grad()
          classifier.zero_grad()
          loss = 0

          output, hidden = encoder(batch['indices'])
          output = output[:,-1,:]
    
          output = classifier(output)
          target = batch['category']

          loss += criterion(output, target)
          epoch_loss+=loss.detach().item()
          loss.backward()

          encoder_optimizer.step()
          classifier_optimizer.step()

      print("Average loss at epoch {}: {}".format(n, epoch_loss/len(dataloader_train)))
      acc = get_accuracy(dataloader_train, encoder, classifier)
      print("Average accuracy at epoch {}: {}".format(n, acc))

  return encoder, classifier