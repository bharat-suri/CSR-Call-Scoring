# -*- coding: utf-8 -*-
"""Inference_fns

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1gtEyI0DrfZVDxgsIGqETSfGBeIPuvqU4
"""

from tqdm import tqdm
import torch
from Preprocessing import preprocess_transcript
from torchtext.data.utils import get_tokenizer
from DataLoader_fns import get_indices

def get_accuracy(dataloader, encoder, classifier):
  total_correct = 0

  for batch in tqdm(dataloader):

    batch_size = len(batch['indices'])

    output, hidden = encoder(batch['indices'])
    output = output[:,-1,:]

    output = classifier(output)

    for i in range(batch_size):

      classification = torch.argmax(output[i]).item()
      target = batch['category'][i]
      if target == classification:
        total_correct+=1

  acc = total_correct/(len(dataloader) * batch_size)
  print("Accuracy: {}".format(acc))
  return acc

def predict(transcript, encoder, classifier, vocab):
  
  word_tokenizer = get_tokenizer('basic_english')
  sents = preprocess_transcript(transcript)
  max_len = 0
  for sent in sents:
    tokens = word_tokenizer(sent)
    if len(tokens) > max_len:
      max_len = len(tokens)

  indices = []
  for sent in sents:
    indices.append(get_indices(sent, max_len, vocab))
  indices = torch.tensor(indices)

  indices = indices.unsqueeze_(0)

  output, hidden = encoder(indices)
  output = output[:,-1,:]

  output = classifier(output)
  classification = torch.argmax(output).item()

  return classification