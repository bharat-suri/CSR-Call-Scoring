# -*- coding: utf-8 -*-
"""DataLoader_fns

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1t2vWLuHjJ9f2XaKZ75UHjFK3AWDiJv2M
"""

import torch
from torchtext.data.utils import get_tokenizer
import pickle

def save_vocab(vocab, path):
    import pickle
    output = open(path, 'wb')
    pickle.dump(vocab, output)
    output.close()

def pad_review(review, max_len):
  num_sents = len(review)
  for i in range(max_len - num_sents):
    review.append('<pad>')
  return review

def get_indices(sentence, max_sent_len, vocab):
  word_tokenizer = get_tokenizer('basic_english')
  tokens = word_tokenizer(sentence)
  indices = [vocab[token] for token in tokens]
  diff = max_sent_len - len(tokens)
  for i in range(diff):
    indices.append(1)
  return indices

def collate(batch):

  word_tokenizer = get_tokenizer('basic_english')
  file = open("vocab",'rb')
  vocab = pickle.load(file)
  file.close()

  max_num_sents = 0
  max_sent_len = 0
  for sample in batch:
    num_sents = len(sample['text'])
    if num_sents > max_num_sents:
      max_num_sents = num_sents
    for sent in sample['text']:
      if len(word_tokenizer(sent)) > max_sent_len:
        max_sent_len = len(word_tokenizer(sent))
  
  for sample in batch:
    sample['text'] = pad_review(sample['text'], max_num_sents)
    sample['indices']= []
    for sent in sample['text']:
      sample['indices'].append(get_indices(sent, max_sent_len, vocab))

  batch_dict = {'text': [], 'indices': [], 'category': []}
  for sample in batch:
    batch_dict['text'].append(sample['text'])
    batch_dict['indices'].append(sample['indices'])
    batch_dict['category'].append(sample['category'])
  batch_dict['indices'] = torch.tensor(batch_dict['indices'])
  batch_dict['category'] = torch.tensor(batch_dict['category'])

  return batch_dict